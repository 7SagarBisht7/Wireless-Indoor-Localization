# -*- coding: utf-8 -*-
"""Wireless Indoor Localization.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/11V1eeNWJ5iIq7Uj02mL_JagMtQ0_j2km

DATA LOADING
"""

import numpy as np

dataset_path = "/content/wifi_localization.txt"
data = np.loadtxt(dataset_path)

print("Dataset shape:", data.shape)

"""DATA PREPROCESSING"""

#CHECKING MISSING VALUES
missing_values = np.isnan(data).any()

if missing_values:
    print("There are missing values in the dataset.")
else:
    print("There are no missing values in the dataset.")

# REMOVING OUTLIERS USING Z_SCORES METHOD
from scipy import stats
z_scores = np.abs(stats.zscore(data))
threshold = 3
cleaned_data = data[(z_scores < threshold).all(axis=1)]


# SPLIT FEATURES AND LABELS
X = cleaned_data[:, :-1]  # Features (signal strengths)
y = cleaned_data[:, -1]   # Labels (rooms)

# NORMALIZATION
from sklearn.preprocessing import StandardScaler
scaler = StandardScaler()
X_normalized = scaler.fit_transform(X)

print("Normalized dataset shape:", X_normalized.shape)


# APPLYING PCA
from sklearn.decomposition import PCA

pca = PCA(n_components=5)
X_pca = pca.fit_transform(X_normalized)
print("Reduced dataset shape after PCA:", X_pca.shape)

"""SPLITTING OF DATASET"""

from sklearn.model_selection import train_test_split
# X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)
X_train, X_test, y_train, y_test = train_test_split(X_pca, y, test_size=0.2, random_state=42)





"""**HYPERPARAMETER TUNNING**"""

from sklearn.model_selection import GridSearchCV

"""HYPERPARAMETER TUNING (FOR LOGISTIC REGRESSION)"""

from sklearn.linear_model import LogisticRegression

# Hyperparameter tuning for Logistic Regression
logistic_param_grid = {'C': [0.001, 0.01, 0.1, 1, 10, 100]}
logistic_grid_search = GridSearchCV(LogisticRegression(max_iter=100000, random_state=42), logistic_param_grid, cv=5, scoring='accuracy')

"""HYPERPARAMETER TUNING (FOR KNN)"""

from sklearn.neighbors import KNeighborsClassifier

# Hyperparameter tuning for KNN
knn_param_grid = {'n_neighbors': [3, 5, 7, 9, 11]}
knn_classifier = KNeighborsClassifier()
knn_grid_search = GridSearchCV(knn_classifier, knn_param_grid, cv=5, scoring='accuracy')

"""HYPERPARAMETER TUNING (FOR RANDOM FOREST)"""

from sklearn.ensemble import RandomForestClassifier

# Hyperparameter tuning for Random Forest
rf_param_grid = {'n_estimators': [50, 100, 150, 200],
                 'max_depth': [None, 10, 20, 30]}
rf_classifier = RandomForestClassifier(random_state=42)
rf_grid_search = GridSearchCV(rf_classifier, rf_param_grid, cv=5, scoring='accuracy')

"""HYPERPARAMETER TUNING (FOR SVM)"""

from sklearn.svm import SVC
svm_param_grid = {'C': [0.1, 1, 10, 100], 'gamma': [1, 0.1, 0.01, 0.001],
                  'kernel': ['rbf', 'linear']}
svm_classifier = SVC(random_state=42)
svm_grid_search = GridSearchCV(svm_classifier, svm_param_grid, cv=5, scoring='accuracy')

"""**TRAINING AND PREDICTION**

For Logistic Regression
"""

#TRAINING THE MODEL
logistic_grid_search.fit(X_train, y_train)
best_logistic = logistic_grid_search.best_estimator_


# PREDICTIONS
y_pred_logistic = best_logistic.predict(X_test)

"""For KNN"""

#TRAINING THE MODEL
knn_grid_search.fit(X_train, y_train)
knn_best = knn_grid_search.best_estimator_

# PREDICTIONS
y_pred_knn = knn_best.predict(X_test)

"""For Random Forest"""

#TRAINING THE MODEL
rf_grid_search.fit(X_train, y_train)
rf_best = rf_grid_search.best_estimator_


# PREDICTIONS
y_pred_rf = rf_best.predict(X_test)

"""For SVM"""

# TRAINING THE MODEL
svm_grid_search.fit(X_train, y_train)
svm_best = svm_grid_search.best_estimator_

# PREDICTIONS
y_pred_svm = svm_best.predict(X_test)

"""**EVALUATION METRICS**"""

from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix

# Calculate metrics for best Logistic Regression model
print("FOR LOGISTIC REGRESSION\n")
accuracy_logistic = accuracy_score(y_test, y_pred_logistic)
print("Accuracy:", accuracy_logistic)

precision_logistic = precision_score(y_test,y_pred_logistic, average='weighted')
print("Precision:", precision_logistic)

recall_logistic = recall_score(y_test,y_pred_logistic, average='weighted')
print("Recall:", recall_logistic)

f1_logistic = f1_score(y_test,y_pred_logistic, average='weighted')
print("F1 score:", f1_logistic)


# Confusion Matrix - Logistic Regression
cm_logistic = confusion_matrix(y_test, y_pred_logistic)
print("Confusion Matrix:\n", cm_logistic)

# Calculate metrics for best KNN model

print("FOR KNN")
accuracy_knn = accuracy_score(y_test, y_pred_knn)
print("Accuracy:", accuracy_knn)

precision_knn = precision_score(y_test, y_pred_knn, average='weighted')
print("PrecisioN:", precision_knn)

recall_knn = recall_score(y_test, y_pred_knn, average='weighted')
print("Recall:", recall_knn)

f1_knn = f1_score(y_test, y_pred_knn, average='weighted')
print("F1 score:", f1_knn)

cm_knn = confusion_matrix(y_test, y_pred_knn)
print("Confusion Matrix:\n", cm_knn)

# Calculate metrics for best Random Forest model
print("FOR RANDOM FOREST")
accuracy_rf = accuracy_score(y_test, y_pred_rf)
print("Accuracy:", accuracy_rf)

precision_rf = precision_score(y_test, y_pred_rf, average='weighted')
print("Precision:", precision_rf)

recall_rf = recall_score(y_test, y_pred_rf, average='weighted')
print("Recall:", recall_rf)

f1_rf = f1_score(y_test, y_pred_rf, average='weighted')
print("F1 score:", f1_rf)

cm_rf = confusion_matrix(y_test, y_pred_rf)
print("Confusion Matrix :\n", cm_rf)

# Calculate metrics for best SVM model
print("FOR SVM")
accuracy_svm = accuracy_score(y_test, y_pred_svm)
print("Accuracy:", accuracy_svm)

precision_svm = precision_score(y_test, y_pred_svm, average='weighted')
print("Precision:", precision_svm)

recall_svm = recall_score(y_test, y_pred_svm, average='weighted')
print("Recall:", recall_svm)

f1_svm = f1_score(y_test, y_pred_svm, average='weighted')
print("F1-score:", f1_svm)

cm_svm = confusion_matrix(y_test, y_pred_svm)
print("Confusion Matrix :\n", cm_svm)



"""**TABLE**"""

import pandas as pd
results = {
    'Model': ['Logistic Regression', 'KNN', 'Random Forest','SVM'],
    'Accuracy': [accuracy_logistic, accuracy_knn, accuracy_rf,accuracy_svm],
    'Precision': [precision_logistic, precision_knn, precision_rf,precision_svm],
    'Recall': [recall_logistic, recall_knn, recall_rf, recall_svm],
    'F1-Score': [f1_logistic, f1_knn, f1_rf, f1_svm]
}

df_results = pd.DataFrame(results)

print(df_results)

"""**CATPLOT (VISUALISATION)**"""

import seaborn as sns
import pandas as pd
import matplotlib.pyplot as plt

results = {
    'Model': ['Logistic Regression', 'KNN', 'Random Forest','SVM',
              'Logistic Regression', 'KNN', 'Random Forest','SVM',
              'Logistic Regression', 'KNN', 'Random Forest','SVM',
              'Logistic Regression', 'KNN', 'Random Forest','SVM'],
    'Metric': ['Accuracy', 'Accuracy', 'Accuracy','Accuracy',
               'Precision', 'Precision', 'Precision','Precision',
               'Recall', 'Recall','Recall', 'Recall',
               'F1-Score','F1-Score','F1-Score','F1-Score'],
    'Score': [accuracy_logistic, accuracy_knn, accuracy_rf,accuracy_svm,
              precision_logistic, precision_knn, precision_rf, precision_svm,
              recall_logistic, recall_knn, recall_rf,recall_svm,
              f1_logistic, f1_knn, f1_rf, f1_svm]
}
df_results = pd.DataFrame(results)


sns.catplot(data=df_results, x='Model', y='Score', hue='Metric', kind='bar',
             height=5, aspect=1)

plt.ylim(0.95,1.0)

plt.title('Indoor Localization Model Comparison')
plt.show()

"""CONFUSION MATRIX"""

# Confusion Matrix - Logistic Regression
def visualize_confusion_matrix(cm, model_name):
    plt.figure(figsize=(8, 6))
    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',
                xticklabels=np.unique(y_test), yticklabels=np.unique(y_test))
    plt.title(f'Confusion Matrix - {model_name}')
    plt.xlabel('Predicted Label')
    plt.ylabel('True Label')
    plt.show()

# Confusion Matrix - Logistic Regression
visualize_confusion_matrix(cm_logistic, "Logistic Regression")

# Confusion Matrix - K-Nearest Neighbors
visualize_confusion_matrix(cm_knn, "K-Nearest Neighbors")

# Confusion Matrix - Random Forests
visualize_confusion_matrix(cm_rf, "Random Forests")

# Confusion Matrix - Support Vector Machines
visualize_confusion_matrix(cm_svm, "Support Vector Machines")